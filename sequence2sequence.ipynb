{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sequence2sequence.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyM7AeIW79Apvsp1KTqNoX48"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"nXBrKvM5U4vJ","colab_type":"code","outputId":"4a80a69e-c14e-499e-fa5e-a5645f64a163","executionInfo":{"status":"ok","timestamp":1588127680608,"user_tz":240,"elapsed":20541,"user":{"displayName":"Iain Graham","photoUrl":"","userId":"00727570204428341338"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')\n","%cd \"/content/drive/My Drive/630Project\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n","/content/drive/My Drive/630Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hAdZ_tAHwjxU","colab_type":"code","colab":{}},"source":["#####################################################################################################################################\n","##### Code and implementation in this notebook was taken/derived from https://www.tensorflow.org/tutorials/text/nmt_with_attention #####\n","#####################################################################################################################################"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VRSw5y-x0PlA","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import unicodedata\n","import re\n","import numpy as np\n","import os\n","import io\n","import time\n","import pickle\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eBUwsEinuPzA","colab_type":"code","colab":{}},"source":["fh = open('x_train_filtered.txt')\n","x_train = []\n","read_lines = fh.readlines()\n","for line in read_lines:\n","    x_train.append(line)\n","fh.close()\n","\n","fh = open('X_test_full.txt')\n","x_test = []\n","read_lines = fh.readlines()\n","for line in read_lines:\n","    x_test.append(line)\n","fh.close()\n","\n","fh = open('y_train_filtered.txt')\n","y_train = []\n","read_lines = fh.readlines()\n","for line in read_lines:\n","    y_train.append(line)\n","fh.close()\n","\n","fh = open('y_test_full.txt')\n","y_test = []\n","read_lines = fh.readlines()\n","for line in read_lines:\n","    y_test.append(line)\n","fh.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yq611s43s-6x","colab_type":"code","outputId":"6f22158f-8a92-4887-d7e4-5998d6683090","executionInfo":{"status":"ok","timestamp":1587911991397,"user_tz":240,"elapsed":254,"user":{"displayName":"Iain Graham","photoUrl":"","userId":"00727570204428341338"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["print(len(x_train))\n","print(len(x_test))\n","print(len(y_train))\n","print(len(y_test))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["31086\n","6908\n","31086\n","6908\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BNsXt23Izk2E","colab_type":"code","colab":{}},"source":["# Splitting articles/summaries into lists of tokens\n","\n","article_tokens = []\n","\n","for article in x_train:\n","    article = article.split()\n","    article_tokens.append(article)\n","    # article_tokens.append('<unk>')\n","#     for word in article:\n","#         article_tokens.append(word)\n","        \n","summary_tokens = []\n","\n","for summary in y_train:\n","    summary = summary.split()\n","    summary_tokens.append(summary)\n","    # summary_tokens.append('<unk>')\n","#     for word in summary:\n","#         summary_tokens.append(word)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FNs2iduOzk4n","colab_type":"code","colab":{}},"source":["def max_length(tensor):\n","    return max(len(t) for t in tensor)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJjcSZzZzk7F","colab_type":"code","colab":{}},"source":["def tokenize(test): \n","    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n","    lang_tokenizer.fit_on_texts(test)\n","    tensor = lang_tokenizer.texts_to_sequences(test)\n","    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n","    return tensor, lang_tokenizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ajgg-ZaDzk9m","colab_type":"code","colab":{}},"source":["input_tensor_train, inp_lang = tokenize(article_tokens)\n","target_tensor_train, targ_lang = tokenize(summary_tokens)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wUbUVWJfzlAC","colab_type":"code","colab":{}},"source":["max_length_targ, max_length_inp = max_length(target_tensor_train), max_length(input_tensor_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uud9cfoLzlFT","colab_type":"code","colab":{}},"source":["BUFFER_SIZE = len(input_tensor_train)\n","BATCH_SIZE = 64\n","steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n","embedding_dim = 300\n","units = 1024\n","vocab_inp_size = len(inp_lang.word_index)+1\n","vocab_tar_size = len(targ_lang.word_index)+1\n","\n","dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u9-T6iPszlH-","colab_type":"code","outputId":"e1e12bce-84fa-40b4-b148-4ed77990253c","executionInfo":{"status":"ok","timestamp":1587912024305,"user_tz":240,"elapsed":9659,"user":{"displayName":"Iain Graham","photoUrl":"","userId":"00727570204428341338"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["example_input_batch, example_target_batch = next(iter(dataset))\n","example_input_batch.shape, example_target_batch.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([64, 250]), TensorShape([64, 75]))"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"Jj5PbPUQzlKu","colab_type":"code","colab":{}},"source":["class Encoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n","    super(Encoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.enc_units = enc_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.enc_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","\n","  def call(self, x, hidden):\n","    x = self.embedding(x)\n","    output, state = self.gru(x, initial_state = hidden)\n","    return output, state\n","\n","  def initialize_hidden_state(self):\n","    return tf.zeros((self.batch_sz, self.enc_units))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kQyuW8UzzlNf","colab_type":"code","outputId":"a5eb8f81-1f59-4a56-d0e8-5c5a62618101","executionInfo":{"status":"ok","timestamp":1587912032096,"user_tz":240,"elapsed":4580,"user":{"displayName":"Iain Graham","photoUrl":"","userId":"00727570204428341338"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n","\n","sample_hidden = encoder.initialize_hidden_state()\n","sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n","print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n","print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Encoder output shape: (batch size, sequence length, units) (64, 250, 1024)\n","Encoder Hidden state shape: (batch size, units) (64, 1024)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G4aVSrw4zlQI","colab_type":"code","colab":{}},"source":["class BahdanauAttention(tf.keras.layers.Layer):\n","  def __init__(self, units):\n","    super(BahdanauAttention, self).__init__()\n","    self.W1 = tf.keras.layers.Dense(units)\n","    self.W2 = tf.keras.layers.Dense(units)\n","    self.V = tf.keras.layers.Dense(1)\n","\n","  def call(self, query, values):\n","\n","    query_with_time_axis = tf.expand_dims(query, 1)\n","\n","    score = self.V(tf.nn.tanh(\n","        self.W1(query_with_time_axis) + self.W2(values)))\n","\n","    attention_weights = tf.nn.softmax(score, axis=1)\n","\n","    context_vector = attention_weights * values\n","    context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","    return context_vector, attention_weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"it2AgE-lzlTC","colab_type":"code","outputId":"5715e6b6-e59a-411f-c1bb-72ef646694a4","executionInfo":{"status":"ok","timestamp":1587912033449,"user_tz":240,"elapsed":3447,"user":{"displayName":"Iain Graham","photoUrl":"","userId":"00727570204428341338"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["attention_layer = BahdanauAttention(10)\n","attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n","\n","print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n","print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Attention result shape: (batch size, units) (64, 1024)\n","Attention weights shape: (batch_size, sequence_length, 1) (64, 250, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-H17yIcYzlV9","colab_type":"code","colab":{}},"source":["class Decoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n","    super(Decoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.dec_units = dec_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.dec_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.fc = tf.keras.layers.Dense(vocab_size)\n","\n","    self.attention = BahdanauAttention(self.dec_units)\n","\n","  def call(self, x, hidden, enc_output):\n","    context_vector, attention_weights = self.attention(hidden, enc_output)\n","    x = self.embedding(x)\n","    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","    output, state = self.gru(x)\n","    output = tf.reshape(output, (-1, output.shape[2]))\n","    x = self.fc(output)\n","\n","    return x, state, attention_weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZcz3YplzlYk","colab_type":"code","outputId":"7cc5ebda-86a3-4f8e-dd68-1571a276cd03","executionInfo":{"status":"ok","timestamp":1587912035755,"user_tz":240,"elapsed":302,"user":{"displayName":"Iain Graham","photoUrl":"","userId":"00727570204428341338"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n","\n","sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n","                                      sample_hidden, sample_output)\n","\n","print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Decoder output shape: (batch_size, vocab size) (64, 10429)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qlr-wBzezlbX","colab_type":"code","colab":{}},"source":["optimizer = tf.keras.optimizers.Adam()\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","\n","  return tf.reduce_mean(loss_)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"89a01n7fzldy","colab_type":"code","colab":{}},"source":["checkpoint_dir = './seq2seq_checkpoints_short'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 encoder=encoder,\n","                                 decoder=decoder)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqIhS4ZN0HJ-","colab_type":"code","colab":{}},"source":["@tf.function\n","def train_step(inp, targ, enc_hidden):\n","  loss = 0\n","\n","  with tf.GradientTape() as tape:\n","    enc_output, enc_hidden = encoder(inp, enc_hidden)\n","\n","    dec_hidden = enc_hidden\n","\n","    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n","\n","    for t in range(1, targ.shape[1]):\n","\n","      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","\n","      loss += loss_function(targ[:, t], predictions)\n","\n","      dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","  batch_loss = (loss / int(targ.shape[1]))\n","\n","  variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","  gradients = tape.gradient(loss, variables)\n","\n","  optimizer.apply_gradients(zip(gradients, variables))\n","\n","  return batch_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3dv4kSX0HMy","colab_type":"code","outputId":"6bf9ba59-2efb-486a-aa83-e997d2cd2126","executionInfo":{"status":"ok","timestamp":1587949261202,"user_tz":240,"elapsed":37190426,"user":{"displayName":"Iain Graham","photoUrl":"","userId":"00727570204428341338"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["EPOCHS = 50\n","\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","\n","  enc_hidden = encoder.initialize_hidden_state()\n","  total_loss = 0\n","\n","  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","    batch_loss = train_step(inp, targ, enc_hidden)\n","    total_loss += batch_loss\n","\n","    if batch % 200 == 0:\n","      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n","                                                   batch,\n","                                                   batch_loss.numpy()))\n","  if (epoch + 1) % 2 == 0:\n","    checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                      total_loss / steps_per_epoch))\n","  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1 Batch 0 Loss 4.9963\n","Epoch 1 Batch 200 Loss 3.7173\n","Epoch 1 Batch 400 Loss 3.3896\n","Epoch 1 Loss 3.6141\n","Time taken for 1 epoch 818.4236869812012 sec\n","\n","Epoch 2 Batch 0 Loss 3.4460\n","Epoch 2 Batch 200 Loss 2.8706\n","Epoch 2 Batch 400 Loss 2.6853\n","Epoch 2 Loss 3.0373\n","Time taken for 1 epoch 741.9432411193848 sec\n","\n","Epoch 3 Batch 0 Loss 2.7638\n","Epoch 3 Batch 200 Loss 2.9746\n","Epoch 3 Batch 400 Loss 2.6580\n","Epoch 3 Loss 2.8355\n","Time taken for 1 epoch 739.898871421814 sec\n","\n","Epoch 4 Batch 0 Loss 2.5502\n","Epoch 4 Batch 200 Loss 2.7552\n","Epoch 4 Batch 400 Loss 2.5834\n","Epoch 4 Loss 2.6986\n","Time taken for 1 epoch 741.30983710289 sec\n","\n","Epoch 5 Batch 0 Loss 2.4900\n","Epoch 5 Batch 200 Loss 2.6363\n","Epoch 5 Batch 400 Loss 2.4842\n","Epoch 5 Loss 2.5678\n","Time taken for 1 epoch 739.8729162216187 sec\n","\n","Epoch 6 Batch 0 Loss 2.4135\n","Epoch 6 Batch 200 Loss 2.4374\n","Epoch 6 Batch 400 Loss 2.4904\n","Epoch 6 Loss 2.4505\n","Time taken for 1 epoch 741.0559024810791 sec\n","\n","Epoch 7 Batch 0 Loss 2.2502\n","Epoch 7 Batch 200 Loss 2.2905\n","Epoch 7 Batch 400 Loss 2.2871\n","Epoch 7 Loss 2.3391\n","Time taken for 1 epoch 739.7255852222443 sec\n","\n","Epoch 8 Batch 0 Loss 2.0854\n","Epoch 8 Batch 200 Loss 2.2787\n","Epoch 8 Batch 400 Loss 2.2446\n","Epoch 8 Loss 2.2297\n","Time taken for 1 epoch 740.9127645492554 sec\n","\n","Epoch 9 Batch 0 Loss 2.0269\n","Epoch 9 Batch 200 Loss 1.9960\n","Epoch 9 Batch 400 Loss 2.2640\n","Epoch 9 Loss 2.1217\n","Time taken for 1 epoch 739.9567170143127 sec\n","\n","Epoch 10 Batch 0 Loss 2.0923\n","Epoch 10 Batch 200 Loss 1.9934\n","Epoch 10 Batch 400 Loss 2.0323\n","Epoch 10 Loss 2.0128\n","Time taken for 1 epoch 741.767471075058 sec\n","\n","Epoch 11 Batch 0 Loss 1.7832\n","Epoch 11 Batch 200 Loss 1.9167\n","Epoch 11 Batch 400 Loss 1.9861\n","Epoch 11 Loss 1.9052\n","Time taken for 1 epoch 740.7496023178101 sec\n","\n","Epoch 12 Batch 0 Loss 1.6313\n","Epoch 12 Batch 200 Loss 1.8030\n","Epoch 12 Batch 400 Loss 1.9989\n","Epoch 12 Loss 1.7994\n","Time taken for 1 epoch 742.588419675827 sec\n","\n","Epoch 13 Batch 0 Loss 1.6932\n","Epoch 13 Batch 200 Loss 1.8155\n","Epoch 13 Batch 400 Loss 1.8981\n","Epoch 13 Loss 1.6925\n","Time taken for 1 epoch 741.7287511825562 sec\n","\n","Epoch 14 Batch 0 Loss 1.5913\n","Epoch 14 Batch 200 Loss 1.6145\n","Epoch 14 Batch 400 Loss 1.6300\n","Epoch 14 Loss 1.5836\n","Time taken for 1 epoch 742.8562164306641 sec\n","\n","Epoch 15 Batch 0 Loss 1.4984\n","Epoch 15 Batch 200 Loss 1.4309\n","Epoch 15 Batch 400 Loss 1.5899\n","Epoch 15 Loss 1.4756\n","Time taken for 1 epoch 741.3158676624298 sec\n","\n","Epoch 16 Batch 0 Loss 1.2702\n","Epoch 16 Batch 200 Loss 1.3330\n","Epoch 16 Batch 400 Loss 1.3588\n","Epoch 16 Loss 1.3711\n","Time taken for 1 epoch 742.4349398612976 sec\n","\n","Epoch 17 Batch 0 Loss 1.2298\n","Epoch 17 Batch 200 Loss 1.2793\n","Epoch 17 Batch 400 Loss 1.2839\n","Epoch 17 Loss 1.2671\n","Time taken for 1 epoch 741.3603661060333 sec\n","\n","Epoch 18 Batch 0 Loss 1.1082\n","Epoch 18 Batch 200 Loss 1.1640\n","Epoch 18 Batch 400 Loss 1.2670\n","Epoch 18 Loss 1.1684\n","Time taken for 1 epoch 742.5765135288239 sec\n","\n","Epoch 19 Batch 0 Loss 1.0011\n","Epoch 19 Batch 200 Loss 1.1230\n","Epoch 19 Batch 400 Loss 1.0392\n","Epoch 19 Loss 1.0861\n","Time taken for 1 epoch 741.274783372879 sec\n","\n","Epoch 20 Batch 0 Loss 0.8860\n","Epoch 20 Batch 200 Loss 1.0072\n","Epoch 20 Batch 400 Loss 1.0734\n","Epoch 20 Loss 0.9896\n","Time taken for 1 epoch 743.9303386211395 sec\n","\n","Epoch 21 Batch 0 Loss 0.8471\n","Epoch 21 Batch 200 Loss 0.9402\n","Epoch 21 Batch 400 Loss 0.9527\n","Epoch 21 Loss 0.9024\n","Time taken for 1 epoch 741.5251774787903 sec\n","\n","Epoch 22 Batch 0 Loss 0.8041\n","Epoch 22 Batch 200 Loss 0.7986\n","Epoch 22 Batch 400 Loss 0.7618\n","Epoch 22 Loss 0.8261\n","Time taken for 1 epoch 743.7423989772797 sec\n","\n","Epoch 23 Batch 0 Loss 0.7433\n","Epoch 23 Batch 200 Loss 0.8228\n","Epoch 23 Batch 400 Loss 0.8431\n","Epoch 23 Loss 0.7520\n","Time taken for 1 epoch 741.4440433979034 sec\n","\n","Epoch 24 Batch 0 Loss 0.6355\n","Epoch 24 Batch 200 Loss 0.7190\n","Epoch 24 Batch 400 Loss 0.6867\n","Epoch 24 Loss 0.7030\n","Time taken for 1 epoch 743.8817958831787 sec\n","\n","Epoch 25 Batch 0 Loss 0.7418\n","Epoch 25 Batch 200 Loss 0.6767\n","Epoch 25 Batch 400 Loss 0.5263\n","Epoch 25 Loss 0.6568\n","Time taken for 1 epoch 742.069721698761 sec\n","\n","Epoch 26 Batch 0 Loss 0.6165\n","Epoch 26 Batch 200 Loss 0.5378\n","Epoch 26 Batch 400 Loss 0.6242\n","Epoch 26 Loss 0.5612\n","Time taken for 1 epoch 744.1985754966736 sec\n","\n","Epoch 27 Batch 0 Loss 0.4913\n","Epoch 27 Batch 200 Loss 0.4998\n","Epoch 27 Batch 400 Loss 0.5406\n","Epoch 27 Loss 0.5004\n","Time taken for 1 epoch 741.7749707698822 sec\n","\n","Epoch 28 Batch 0 Loss 0.4366\n","Epoch 28 Batch 200 Loss 0.4549\n","Epoch 28 Batch 400 Loss 0.4573\n","Epoch 28 Loss 0.4559\n","Time taken for 1 epoch 743.679544210434 sec\n","\n","Epoch 29 Batch 0 Loss 0.4425\n","Epoch 29 Batch 200 Loss 0.4229\n","Epoch 29 Batch 400 Loss 0.4152\n","Epoch 29 Loss 0.4180\n","Time taken for 1 epoch 741.6526551246643 sec\n","\n","Epoch 30 Batch 0 Loss 0.3330\n","Epoch 30 Batch 200 Loss 0.3596\n","Epoch 30 Batch 400 Loss 0.3744\n","Epoch 30 Loss 0.3777\n","Time taken for 1 epoch 744.1900329589844 sec\n","\n","Epoch 31 Batch 0 Loss 0.3343\n","Epoch 31 Batch 200 Loss 0.3328\n","Epoch 31 Batch 400 Loss 0.3656\n","Epoch 31 Loss 0.3481\n","Time taken for 1 epoch 741.9485664367676 sec\n","\n","Epoch 32 Batch 0 Loss 0.3056\n","Epoch 32 Batch 200 Loss 0.2996\n","Epoch 32 Batch 400 Loss 0.3618\n","Epoch 32 Loss 0.3206\n","Time taken for 1 epoch 744.1469769477844 sec\n","\n","Epoch 33 Batch 0 Loss 0.2356\n","Epoch 33 Batch 200 Loss 0.2680\n","Epoch 33 Batch 400 Loss 0.3163\n","Epoch 33 Loss 0.2860\n","Time taken for 1 epoch 741.5009789466858 sec\n","\n","Epoch 34 Batch 0 Loss 0.2471\n","Epoch 34 Batch 200 Loss 0.2623\n","Epoch 34 Batch 400 Loss 0.2640\n","Epoch 34 Loss 0.2662\n","Time taken for 1 epoch 744.0931179523468 sec\n","\n","Epoch 35 Batch 0 Loss 0.2080\n","Epoch 35 Batch 200 Loss 0.2364\n","Epoch 35 Batch 400 Loss 0.2334\n","Epoch 35 Loss 0.2451\n","Time taken for 1 epoch 741.873613357544 sec\n","\n","Epoch 36 Batch 0 Loss 0.2305\n","Epoch 36 Batch 200 Loss 0.2085\n","Epoch 36 Batch 400 Loss 0.2819\n","Epoch 36 Loss 0.2241\n","Time taken for 1 epoch 744.3262469768524 sec\n","\n","Epoch 37 Batch 0 Loss 0.2028\n","Epoch 37 Batch 200 Loss 0.1802\n","Epoch 37 Batch 400 Loss 0.2305\n","Epoch 37 Loss 0.2027\n","Time taken for 1 epoch 741.7503621578217 sec\n","\n","Epoch 38 Batch 0 Loss 0.1810\n","Epoch 38 Batch 200 Loss 0.1612\n","Epoch 38 Batch 400 Loss 0.1771\n","Epoch 38 Loss 0.1831\n","Time taken for 1 epoch 743.6609375476837 sec\n","\n","Epoch 39 Batch 0 Loss 0.1485\n","Epoch 39 Batch 200 Loss 0.1881\n","Epoch 39 Batch 400 Loss 0.1860\n","Epoch 39 Loss 0.1754\n","Time taken for 1 epoch 741.272946357727 sec\n","\n","Epoch 40 Batch 0 Loss 0.1470\n","Epoch 40 Batch 200 Loss 0.1615\n","Epoch 40 Batch 400 Loss 0.1829\n","Epoch 40 Loss 0.1717\n","Time taken for 1 epoch 743.7999632358551 sec\n","\n","Epoch 41 Batch 0 Loss 0.1728\n","Epoch 41 Batch 200 Loss 0.1403\n","Epoch 41 Batch 400 Loss 0.1558\n","Epoch 41 Loss 0.1698\n","Time taken for 1 epoch 741.4692842960358 sec\n","\n","Epoch 42 Batch 0 Loss 0.1269\n","Epoch 42 Batch 200 Loss 0.1333\n","Epoch 42 Batch 400 Loss 0.1773\n","Epoch 42 Loss 0.1512\n","Time taken for 1 epoch 743.6363925933838 sec\n","\n","Epoch 43 Batch 0 Loss 0.1340\n","Epoch 43 Batch 200 Loss 0.1692\n","Epoch 43 Batch 400 Loss 0.1343\n","Epoch 43 Loss 0.1417\n","Time taken for 1 epoch 741.6586091518402 sec\n","\n","Epoch 44 Batch 0 Loss 0.0878\n","Epoch 44 Batch 200 Loss 0.1132\n","Epoch 44 Batch 400 Loss 0.1208\n","Epoch 44 Loss 0.1214\n","Time taken for 1 epoch 743.9093286991119 sec\n","\n","Epoch 45 Batch 0 Loss 0.1025\n","Epoch 45 Batch 200 Loss 0.1105\n","Epoch 45 Batch 400 Loss 0.1328\n","Epoch 45 Loss 0.1215\n","Time taken for 1 epoch 741.4794099330902 sec\n","\n","Epoch 46 Batch 0 Loss 0.1293\n","Epoch 46 Batch 200 Loss 0.1271\n","Epoch 46 Batch 400 Loss 0.1862\n","Epoch 46 Loss 0.1432\n","Time taken for 1 epoch 743.8096528053284 sec\n","\n","Epoch 47 Batch 0 Loss 0.1300\n","Epoch 47 Batch 200 Loss 0.1430\n","Epoch 47 Batch 400 Loss 0.1480\n","Epoch 47 Loss 0.1394\n","Time taken for 1 epoch 741.4714517593384 sec\n","\n","Epoch 48 Batch 0 Loss 0.1140\n","Epoch 48 Batch 200 Loss 0.1098\n","Epoch 48 Batch 400 Loss 0.1184\n","Epoch 48 Loss 0.1166\n","Time taken for 1 epoch 743.7223582267761 sec\n","\n","Epoch 49 Batch 0 Loss 0.1095\n","Epoch 49 Batch 200 Loss 0.1037\n","Epoch 49 Batch 400 Loss 0.1098\n","Epoch 49 Loss 0.1026\n","Time taken for 1 epoch 742.147435426712 sec\n","\n","Epoch 50 Batch 0 Loss 0.0795\n","Epoch 50 Batch 200 Loss 0.0918\n","Epoch 50 Batch 400 Loss 0.2727\n","Epoch 50 Loss 0.1122\n","Time taken for 1 epoch 743.9725713729858 sec\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CxreXfZb0Hde","colab_type":"code","colab":{}},"source":["def preprocess_sentence(w):\n","    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n","    w = re.sub(r'[\" \"]+', \" \", w)\n","    w = re.sub('\\d', '#', w)\n","    w = w.strip()\n","    w = '<start> ' + w + ' <end>'\n","    return w"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pTro5Umlzlgr","colab_type":"code","colab":{}},"source":["def evaluate(sentence):\n","  attention_plot = np.zeros((max_length_targ, max_length_inp))\n","\n","  sentence = preprocess_sentence(sentence)\n","  temp = []\n","  tokens = sentence.split()\n","  for token in tokens:\n","    if token in list(inp_lang.index_word.values()):\n","      temp.append(token)\n","    else:\n","      temp.append('<unk>')\n","\n","  sentence = \" \".join(temp)\n","\n","  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n","  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n","                                                         maxlen=max_length_inp,\n","                                                         padding='post')\n","  inputs = tf.convert_to_tensor(inputs)\n","\n","  result = ''\n","\n","  hidden = [tf.zeros((1, units))]\n","  enc_out, enc_hidden = encoder(inputs, hidden)\n","\n","  dec_hidden = enc_hidden\n","  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n","\n","  for t in range(max_length_targ):\n","    predictions, dec_hidden, attention_weights = decoder(dec_input,\n","                                                         dec_hidden,\n","                                                         enc_out)\n","\n","    attention_weights = tf.reshape(attention_weights, (-1, ))\n","    attention_plot[t] = attention_weights.numpy()\n","\n","    predicted_id = tf.argmax(predictions[0]).numpy()\n","\n","    result += targ_lang.index_word[predicted_id] + ' '\n","\n","    if targ_lang.index_word[predicted_id] == '<end>':\n","      return result, sentence, attention_plot\n","\n","    dec_input = tf.expand_dims([predicted_id], 0)\n","\n","  return result, sentence, attention_plot"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QygszaJKF4B2","colab_type":"code","colab":{}},"source":["def plot_attention(attention, sentence, predicted_sentence):\n","  fig = plt.figure(figsize=(10,10))\n","  ax = fig.add_subplot(1, 1, 1)\n","  ax.matshow(attention, cmap='viridis')\n","\n","  fontdict = {'fontsize': 14}\n","\n","  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n","  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n","\n","  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s5DAW_FAF4Lj","colab_type":"code","colab":{}},"source":["def translate(sentence):\n","  result, sentence, attention_plot = evaluate(sentence)\n","  return result"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9sYdxU2dF4PP","colab_type":"code","outputId":"a5595dab-cdf7-4a43-efb0-123d6ce0c05f","executionInfo":{"status":"ok","timestamp":1587949880978,"user_tz":240,"elapsed":11979,"user":{"displayName":"Iain Graham","photoUrl":"","userId":"00727570204428341338"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fc915256048>"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"uebBkHyHW6mJ","colab_type":"code","colab":{}},"source":["fh = open('X_test_full.txt')\n","x_test = []\n","read_lines = fh.readlines()\n","for line in read_lines:\n","    x_test.append(line)\n","fh.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JEyU4ouZpYv-","colab_type":"code","colab":{}},"source":["seq2seq_summaries = [translate(x) for x in x_test]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"weJ79uejQN5p","colab_type":"code","colab":{}},"source":["with open(\"seq2seq_summaries.txt\", \"w\") as filehandle:\n","    for listitem in seq2seq_summaries:\n","        filehandle.write('%s\\n' % listitem)"],"execution_count":0,"outputs":[]}]}